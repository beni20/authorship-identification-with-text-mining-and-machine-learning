{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pathlib\n",
    "import bs4 as bs\n",
    "import re\n",
    "import os\n",
    "import pytest \n",
    "import glob\n",
    "import pandas as pd\n",
    "import chardet\n",
    "from chardet.universaldetector import UniversalDetector\n",
    "\n",
    "\n",
    "dataset_folder = 'data'\n",
    "detector = UniversalDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "authorIDs = [3574878, 2845196, 3444474, 3445677, 828046, 4284264, 3498812, 4137740, 3662461, 3363271]\n",
    "filenames = []\n",
    "\n",
    "\n",
    "\n",
    "for id in authorIDs:\n",
    " filename = glob.glob('blogs/' + str(id) + '.*.xml')\n",
    " filenames.append(filename[0])\n",
    "    \n",
    "for filename in filenames:\n",
    "#for filename in glob.glob('blogs/*.xml'):\n",
    "    print(filename)\n",
    "    detector.reset()\n",
    "    for line in open(filename, 'rb'):\n",
    "        detector.feed(line)\n",
    "        if detector.done: break\n",
    "    detector.close()\n",
    "    print(detector.result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post:\n",
    "    author_number: int\n",
    "    gender: str\n",
    "    age: int\n",
    "    industry: str\n",
    "    star_sign: str\n",
    "    date: str  \n",
    "    post: str\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            key: getattr(self, key)\n",
    "            for key in ['author_number', 'gender', 'age', 'industry', 'star_sign', 'date', 'post']\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_file(filename) -> List[\"Post\"]:\n",
    "        # The last element is the file extension, which we don't care about\n",
    "        # example file format is: 5144.male.25.indUnk.Scorpio.xml\n",
    "        age, author_number, gender, industry, star_sign = Post.extract_attributes_from_filename(filename)\n",
    "\n",
    "        posts = []\n",
    "        \n",
    "        encoding = Post.get_encoding(filename);\n",
    "        xml_source = open(filename, errors='surrogateescape', encoding=encoding).read()\n",
    "        #xml_source = open(filename, errors='strict', encoding=encoding).read()\n",
    "        #xml_source = open(filename, errors='replace').read()\n",
    "        xml_soup = bs.BeautifulSoup(xml_source, \"lxml\")\n",
    "        xml_posts = xml_soup.find_all(\"post\")\n",
    "        xml_dates = xml_soup.find_all(\"date\")\n",
    "        #print(posts[0].text)\n",
    "        \n",
    "        for i in range(0, len(xml_posts)):\n",
    "            new_post = Post.create_from_attributes(\n",
    "                author_number, gender, age, industry, star_sign, xml_dates[i].text.strip(), xml_posts[i].text.strip())\n",
    "            posts.append(new_post)\n",
    "\n",
    "        return posts\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_attributes_from_filename(filename):\n",
    "        base_filename = pathlib.Path(filename).name  # Get just the filename component\n",
    "        author_number, gender, age, industry, star_sign, _ = base_filename.split(\".\")\n",
    "        author_number = int(author_number)\n",
    "        age = int(age)\n",
    "        return age, author_number, gender, industry, star_sign\n",
    "\n",
    "    @staticmethod\n",
    "    def get_encoding(filename):\n",
    "        detector.reset()\n",
    "        for line in open(filename, 'rb'):\n",
    "            detector.feed(line)\n",
    "            if detector.done: break\n",
    "        detector.close()\n",
    "        return detector.result['encoding']\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_from_attributes(author_number, gender, age, industry, star_sign, date, post):\n",
    "        p = Post()\n",
    "        p.author_number = author_number\n",
    "        p.gender = gender\n",
    "        p.age = age\n",
    "        p.industry = industry\n",
    "        p.star_sign = star_sign\n",
    "        p.date = date  \n",
    "        p.post = post  \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well... I am unsure how to start this new blogging stuff...guess I will just reflect a little and see how it goes.  Have you ever been stuck in a matrix? I have! To me it was like being in a padded, suspended time warp during the early part of  my adult life. A time that lasted over 12 years. That shouldn’t happen to anyone...and shouldn’t have happen to me. But it did. I was 23 , a new single mom...no friends...no job...and not much family to speak of. I had to make money and take care of my son... I couldn’t afford to live on my own so me and my child stayed with my parents... I went back to school and learned a vocation. Then... tried for years and years to make a difference...be somebody and amount to something for my sons sake...the matrix I was in got thicker and harder to escape from...I couldn’t do enough for anyone. My parents, my employer, so called friends, relatives.... it was like total non-acceptance...I felt laughed at and demeaned.  (Like a RedHeaded Step Child.)  I had a vision of the way I wanted my life and it wasn’t happening. Feeling like every move I made no matter how positive only enabled those around me to throw dirt on my emotions and aspirations and even me. They would throw dirt on me! Spreading slanderous rumor making ugly innuendo... I would try and try to ignore and endure.  Oh!Gaud; How did I get there?  So much time had gone by in this continuum...my ideas were lost. Buried in the gook and gum of this matrix intra-cellular structure...  I got really  mad  one day and more or less threw my hands up in despare...then... feeling terribly,terribly  angry ... I suddenly broke free from the matrix by desiding right then and there ...That I was going to make a move. A move that would  change  my life and those that went with me for the better.  The  anger  did it...I was fed up...I had gotten to the point where I hated everyone around me...I had to get out or die trying...  It took alot out of me. It was a draining yet somehow refreshing experience.... In a way I was reborn...a new beginning... a time to be  me  and a very liberating change...  I had escaped.... It was my Independance Day...\n",
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "p = Post.load_from_file('data\\\\3363271.female.27.Student.Virgo.xml')\n",
    "e = Post.extract_attributes_from_filename('data\\\\3363271.female.27.Student.Virgo.xml')\n",
    "c = Post.get_encoding('data\\\\4137740.female.47.indUnk.Libra.xml')\n",
    "p = Post.load_from_file('data\\\\4137740.female.47.indUnk.Libra.xml')\n",
    "print(p[0].post)\n",
    "#print(e)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_id_pattern = re.compile(r\"(\\d{3,})\\..*\\..*\\..*\\..*\\.xml\")\n",
    "\n",
    "def get_filename_id(filename):\n",
    "    # We use search, not match, as we don't care if it's not the whole string\n",
    "    match = filename_id_pattern.search(filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        raise ValueError(f\"Could not find an ID in filename {filename}\")\n",
    "        \n",
    "def get_all_xml_files_in_folder(dataset_folder):\n",
    "    return glob.glob(os.path.join(dataset_folder, \"*.xml\"))\n",
    "\n",
    "def load_dataset_from_raw(dataset_folder):\n",
    "    all_posts = []\n",
    "    #print(get_all_xml_files_in_folder(dataset_folder))\n",
    "    for filename in get_all_xml_files_in_folder(dataset_folder):\n",
    "        current_posts = Post.load_from_file(filename)\n",
    "        all_posts.extend(current_posts)\n",
    "    return all_posts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(all_posts, output_file):\n",
    "    dataset = pd.DataFrame([post.to_dict() for post in all_posts])\n",
    "    dataset.to_parquet(output_file, compression='gzip')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_dataset(input_file):\n",
    "    return pd.read_parquet(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset_from_raw(dataset_folder)\n",
    "save_dataset(raw_dataset, 'posts1.data')\n",
    "#processed_dataset = load_dataset(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_number</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>star_sign</th>\n",
       "      <th>date</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>31,May,2004</td>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>29,May,2004</td>\n",
       "      <td>My four-year old never stops talking.  She'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>Actually it's not raining yet, but I bought 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>Ha! Just set up my RSS feed - that is so easy!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>28,May,2004</td>\n",
       "      <td>Oh, which just reminded me, we were talking ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_number  gender  age industry star_sign         date  \\\n",
       "0        1000331  female   37   indUnk       Leo  31,May,2004   \n",
       "1        1000331  female   37   indUnk       Leo  29,May,2004   \n",
       "2        1000331  female   37   indUnk       Leo  28,May,2004   \n",
       "3        1000331  female   37   indUnk       Leo  28,May,2004   \n",
       "4        1000331  female   37   indUnk       Leo  28,May,2004   \n",
       "\n",
       "                                                post  \n",
       "0  Well, everyone got up and going this morning. ...  \n",
       "1  My four-year old never stops talking.  She'll ...  \n",
       "2  Actually it's not raining yet, but I bought 15...  \n",
       "3  Ha! Just set up my RSS feed - that is so easy!...  \n",
       "4  Oh, which just reminded me, we were talking ab...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_filename = \"posts1.data\"\n",
    "all_posts = load_dataset(dataset_filename)\n",
    "\n",
    "all_posts.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3662461 3662461 3662461 3662461 3662461 4137740 4137740  828046  828046\n",
      "  828046  828046  828046  828046  828046  828046  828046  828046  828046\n",
      "  828046]\n"
     ]
    }
   ],
   "source": [
    "#example_authors = [3574878, 2845196, 3444474, 3445677, 828046, 4284264, 3498812, 4137740, 3662461, 3363271]\n",
    "example_authors = [828046, 4137740, 3662461 ]\n",
    "\n",
    "def get_sampled_authors(dataset, sample_authors):\n",
    "    mask = dataset['author_number'].isin(sample_authors)\n",
    "    return dataset[mask]\n",
    "\n",
    "\n",
    "sample = get_sampled_authors(all_posts, example_authors)\n",
    "    \n",
    "\n",
    "documents = sample['post'].values\n",
    "authors = sample['author_number'].values\n",
    "print(authors) #19 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 5, 14, 5)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "documents_train, documents_test, authors_train, authors_test = train_test_split(documents, authors)\n",
    "\n",
    "len(documents_train), len(documents_test), len(authors_train), len(authors_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 374)\n",
      "(5, 374)\n",
      "[3662461 3662461 4137740  828046  828046]\n",
      "[3662461  828046  828046  828046  828046]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      828046       0.50      1.00      0.67         2\n",
      "     3662461       1.00      0.50      0.67         2\n",
      "     4137740       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.50      0.44         5\n",
      "weighted avg       0.60      0.60      0.53         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luke\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#preprocessor = TfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
    "preprocessor = TfidfVectorizer(analyzer='word')\n",
    "X_train = preprocessor.fit_transform(documents_train)\n",
    "print(X_train.shape)\n",
    "X_test = preprocessor.transform(documents_test)\n",
    "print(X_test.shape)\n",
    "\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, authors_train)\n",
    "\n",
    "authors_predicted = model.predict(X_test)\n",
    "\n",
    "print(authors_test)\n",
    "print(authors_predicted)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(authors_test, authors_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    }
   ],
   "source": [
    "feature_names = preprocessor.get_feature_names()\n",
    "print(len(feature_names))\n",
    "dense = X_train.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          20      2074        60       70s  ability  accessories   achieve  \\\n",
      "0   0.000000  0.000000  0.081919  0.000000  0.00000     0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  0.194517  0.00000     0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "5   0.239248  0.239248  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.00000     0.153067  0.153067   \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  0.000000  0.06367     0.000000  0.000000   \n",
      "12  0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "13  0.000000  0.000000  0.000000  0.000000  0.00000     0.000000  0.000000   \n",
      "\n",
      "         act       add    afraid  ...   wishing      with   within       won  \\\n",
      "0   0.000000  0.081919  0.000000  ...  0.000000  0.047880  0.00000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000   \n",
      "2   0.194517  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000   \n",
      "4   0.000000  0.000000  0.190738  ...  0.110188  0.000000  0.00000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.239248   \n",
      "6   0.000000  0.000000  0.000000  ...  0.000000  0.089464  0.00000  0.000000   \n",
      "7   0.000000  0.000000  0.000000  ...  0.000000  0.132809  0.00000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  ...  0.000000  0.142428  0.00000  0.000000   \n",
      "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  ...  0.000000  0.074427  0.06367  0.000000   \n",
      "12  0.000000  0.000000  0.141205  ...  0.000000  0.000000  0.00000  0.000000   \n",
      "13  0.000000  0.000000  0.000000  ...  0.000000  0.172326  0.00000  0.000000   \n",
      "\n",
      "      wrong      year     years       yes       yet       you  \n",
      "0   0.00000  0.000000  0.000000  0.000000  0.000000  0.114045  \n",
      "1   0.00000  0.000000  0.000000  0.573453  0.000000  0.000000  \n",
      "2   0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3   0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4   0.00000  0.000000  0.000000  0.000000  0.110188  0.000000  \n",
      "5   0.00000  0.239248  0.239248  0.000000  0.000000  0.000000  \n",
      "6   0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "7   0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "8   0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9   0.00000  0.000000  0.000000  0.000000  0.000000  0.150051  \n",
      "10  0.00000  0.000000  0.000000  0.000000  0.000000  0.174051  \n",
      "11  0.06367  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "12  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "13  0.00000  0.000000  0.000000  0.000000  0.000000  0.205231  \n",
      "\n",
      "[14 rows x 374 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
