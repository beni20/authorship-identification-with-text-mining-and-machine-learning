{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('test.txt', 'wb').write(bytes([65, 66, 67, 255, 192,193]))\n",
    "open(filename, encoding='Windows-1252', errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 108644)\t4\n",
      "  (0, 110106)\t1\n",
      "  (0, 57577)\t2\n",
      "  (0, 24398)\t2\n",
      "  (0, 79534)\t1\n",
      "  (0, 100942)\t1\n",
      "  (0, 37154)\t1\n",
      "  (0, 45141)\t1\n",
      "  (0, 70570)\t1\n",
      "  (0, 78701)\t2\n",
      "  (0, 101084)\t4\n",
      "  (0, 32499)\t4\n",
      "  (0, 92157)\t1\n",
      "  (0, 100827)\t6\n",
      "  (0, 79461)\t1\n",
      "  (0, 39275)\t1\n",
      "  (0, 60326)\t2\n",
      "  (0, 42332)\t1\n",
      "  (0, 96432)\t1\n",
      "  (0, 67137)\t1\n",
      "  (0, 101732)\t1\n",
      "  (0, 27703)\t1\n",
      "  (0, 49871)\t2\n",
      "  (0, 65338)\t1\n",
      "  (0, 14106)\t1\n",
      "  :\t:\n",
      "  (11313, 55901)\t1\n",
      "  (11313, 93448)\t1\n",
      "  (11313, 97535)\t1\n",
      "  (11313, 93393)\t1\n",
      "  (11313, 109366)\t1\n",
      "  (11313, 102215)\t1\n",
      "  (11313, 29148)\t1\n",
      "  (11313, 26901)\t1\n",
      "  (11313, 94401)\t1\n",
      "  (11313, 89686)\t1\n",
      "  (11313, 80827)\t1\n",
      "  (11313, 72219)\t1\n",
      "  (11313, 32984)\t1\n",
      "  (11313, 82912)\t1\n",
      "  (11313, 99934)\t1\n",
      "  (11313, 96505)\t1\n",
      "  (11313, 72102)\t1\n",
      "  (11313, 32981)\t1\n",
      "  (11313, 82692)\t1\n",
      "  (11313, 101854)\t1\n",
      "  (11313, 66399)\t1\n",
      "  (11313, 63405)\t1\n",
      "  (11313, 61366)\t1\n",
      "  (11313, 7462)\t1\n",
      "  (11313, 109600)\t1\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = vectorizer.fit_transform(newsgroups.data)\n",
    "print(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 965, column 585 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\luke\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3343\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-35-fd3efb8fc0c6>\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    document = parse('blogs/5114.male.25.indUnk.Scorpio.xml')\n",
      "  File \u001b[0;32m\"C:\\Users\\luke\\anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[0m, line \u001b[0;32m1202\u001b[0m, in \u001b[0;35mparse\u001b[0m\n    tree.parse(source, parser)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\luke\\anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[1;36m, line \u001b[1;32m595\u001b[1;36m, in \u001b[1;35mparse\u001b[1;36m\u001b[0m\n\u001b[1;33m    self._root = parser._parse_whole(source)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mParseError\u001b[0m\u001b[1;31m:\u001b[0m not well-formed (invalid token): line 965, column 585\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse\n",
    "document = parse('blogs/5114.male.25.indUnk.Scorpio.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<post>\n",
      "\n",
      "\n",
      "       \n",
      "      Slashdot raises lots of  urlLink interesting thoughts about banner ads .  The idea is to let users control the ad delivery, and even to allow users to comment on ads.\n",
      "     \n",
      "\n",
      "    \n",
      "</post>\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import re\n",
    "\n",
    "#filename = 'blogs/11253.male.26.Technology.Aquarius.xml'\n",
    "filename = 'blogs/5114.male.25.indUnk.Scorpio.xml'\n",
    "filenameAssert = re.search(\"^.*\\D\\d{2}\\D.*xml$\", filename)\n",
    "assert filenameAssert != None \n",
    "\n",
    "\n",
    "#assert filename.contains\n",
    "#source = open('blogs/5114.male.25.indUnk.Scorpio.xml').read()\n",
    "source = open(filename).read()\n",
    "\n",
    "soup = bs.BeautifulSoup(source, \"lxml\")\n",
    "posts = soup.find_all(\"post\")\n",
    "dates = soup.find_all(\"date\")\n",
    "print(posts[0])\n",
    "\n",
    "post = posts[0].text\n",
    "\n",
    "assert \"Slashdot raises lots of \" in post\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\\n\\n\\n       \\n      Slashdot raises lots of ...</td>\n",
       "      <td>[28,February,2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\\n\\n\\n       \\n       urlLink  The Merchants ...</td>\n",
       "      <td>[27,February,2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\\n\\n\\n       \\n       urlLink ATMs dispensing...</td>\n",
       "      <td>[26,February,2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\\n\\n\\n       \\n      My chair started squeaki...</td>\n",
       "      <td>[22,February,2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\\n\\n\\n       \\n      The New York Press has a...</td>\n",
       "      <td>[20,February,2001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[\\n\\n\\n       \\n      I'm looking for someone ...</td>\n",
       "      <td>[06,April,2004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[\\n\\n\\n       \\n      I'm pleased to announce ...</td>\n",
       "      <td>[17,May,2004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[\\n\\n\\n       \\n      I'm using this blog to p...</td>\n",
       "      <td>[10,May,2004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[\\n\\n\\n       \\n      I'm blogging a lot more ...</td>\n",
       "      <td>[28,June,2004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[[\\n\\n\\n       \\n      Slashdot raises lots of...</td>\n",
       "      <td>[[28,February,2001], [27,February,2001], [26,F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  post  \\\n",
       "0    [\\n\\n\\n       \\n      Slashdot raises lots of ...   \n",
       "1    [\\n\\n\\n       \\n       urlLink  The Merchants ...   \n",
       "2    [\\n\\n\\n       \\n       urlLink ATMs dispensing...   \n",
       "3    [\\n\\n\\n       \\n      My chair started squeaki...   \n",
       "4    [\\n\\n\\n       \\n      The New York Press has a...   \n",
       "..                                                 ...   \n",
       "193  [\\n\\n\\n       \\n      I'm looking for someone ...   \n",
       "194  [\\n\\n\\n       \\n      I'm pleased to announce ...   \n",
       "195  [\\n\\n\\n       \\n      I'm using this blog to p...   \n",
       "196  [\\n\\n\\n       \\n      I'm blogging a lot more ...   \n",
       "197  [[\\n\\n\\n       \\n      Slashdot raises lots of...   \n",
       "\n",
       "                                                  date  \n",
       "0                                   [28,February,2001]  \n",
       "1                                   [27,February,2001]  \n",
       "2                                   [26,February,2001]  \n",
       "3                                   [22,February,2001]  \n",
       "4                                   [20,February,2001]  \n",
       "..                                                 ...  \n",
       "193                                    [06,April,2004]  \n",
       "194                                      [17,May,2004]  \n",
       "195                                      [10,May,2004]  \n",
       "196                                     [28,June,2004]  \n",
       "197  [[28,February,2001], [27,February,2001], [26,F...  \n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'post': posts, 'date': dates}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 2)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import glob\n",
    "from chardet.universaldetector import UniversalDetector\n",
    "\n",
    "authorIDs = [3574878, 2845196, 3444474, 3445677, 828046, 4284264, 3498812, 4137740, 3662461, 3363271]\n",
    "filenames = []\n",
    "\n",
    "detector = UniversalDetector()\n",
    "\n",
    "for id in authorIDs:\n",
    " filename = glob.glob('blogs/' + str(id) + '.*.xml')\n",
    " filenames.append(filename[0])\n",
    "    \n",
    "for filename in filenames:\n",
    "#for filename in glob.glob('blogs/*.xml'):\n",
    "    print(filename)\n",
    "    detector.reset()\n",
    "    for line in open(filename, 'rb'):\n",
    "        detector.feed(line)\n",
    "        if detector.done: break\n",
    "    detector.close()\n",
    "    print(detector.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 108644)\t4\n",
      "  (0, 110106)\t1\n",
      "  (0, 57577)\t2\n",
      "  (0, 24398)\t2\n",
      "  (0, 79534)\t1\n",
      "  (0, 100942)\t1\n",
      "  (0, 37154)\t1\n",
      "  (0, 45141)\t1\n",
      "  (0, 70570)\t1\n",
      "  (0, 78701)\t2\n",
      "  (0, 101084)\t4\n",
      "  (0, 32499)\t4\n",
      "  (0, 92157)\t1\n",
      "  (0, 100827)\t6\n",
      "  (0, 79461)\t1\n",
      "  (0, 39275)\t1\n",
      "  (0, 60326)\t2\n",
      "  (0, 42332)\t1\n",
      "  (0, 96432)\t1\n",
      "  (0, 67137)\t1\n",
      "  (0, 101732)\t1\n",
      "  (0, 27703)\t1\n",
      "  (0, 49871)\t2\n",
      "  (0, 65338)\t1\n",
      "  (0, 14106)\t1\n",
      "  :\t:\n",
      "  (11313, 55901)\t1\n",
      "  (11313, 93448)\t1\n",
      "  (11313, 97535)\t1\n",
      "  (11313, 93393)\t1\n",
      "  (11313, 109366)\t1\n",
      "  (11313, 102215)\t1\n",
      "  (11313, 29148)\t1\n",
      "  (11313, 26901)\t1\n",
      "  (11313, 94401)\t1\n",
      "  (11313, 89686)\t1\n",
      "  (11313, 80827)\t1\n",
      "  (11313, 72219)\t1\n",
      "  (11313, 32984)\t1\n",
      "  (11313, 82912)\t1\n",
      "  (11313, 99934)\t1\n",
      "  (11313, 96505)\t1\n",
      "  (11313, 72102)\t1\n",
      "  (11313, 32981)\t1\n",
      "  (11313, 82692)\t1\n",
      "  (11313, 101854)\t1\n",
      "  (11313, 66399)\t1\n",
      "  (11313, 63405)\t1\n",
      "  (11313, 61366)\t1\n",
      "  (11313, 7462)\t1\n",
      "  (11313, 109600)\t1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for filename in glob.glob('blogs/*'):\n",
    " filenames.append(filename)\n",
    "\n",
    "data = []\n",
    "all_posts = []\n",
    "for filename in filenames[0:100]:\n",
    "    #print(filename)\n",
    "    source = open(filename, errors='replace').read()\n",
    "    soup = bs.BeautifulSoup(source, \"xml\")\n",
    "    posts = soup.find_all(\"post\")\n",
    "    dates = soup.find_all(\"date\")\n",
    "    for i in range(1, len(posts)):\n",
    "         data.append({'blog': filename, 'posts': posts[i].text, 'dates': dates[i].text})\n",
    "         all_posts.append(posts[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog</th>\n",
       "      <th>posts</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogs\\1000331.female.37.indUnk.Leo.xml</td>\n",
       "      <td>\\n\\n\\t \\n      My four-year old never stops ta...</td>\n",
       "      <td>29,May,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogs\\1000331.female.37.indUnk.Leo.xml</td>\n",
       "      <td>\\n\\n\\t \\n      Actually it's not raining yet, ...</td>\n",
       "      <td>28,May,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blogs\\1000331.female.37.indUnk.Leo.xml</td>\n",
       "      <td>\\n\\n\\t \\n      Ha! Just set up my RSS feed - t...</td>\n",
       "      <td>28,May,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blogs\\1000331.female.37.indUnk.Leo.xml</td>\n",
       "      <td>\\n\\n\\t \\n      Oh, which just reminded me, we ...</td>\n",
       "      <td>28,May,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blogs\\1000331.female.37.indUnk.Leo.xml</td>\n",
       "      <td>\\n\\n\\t \\n      I've tried starting blog after ...</td>\n",
       "      <td>28,May,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15909</th>\n",
       "      <td>blogs\\1089670.female.17.Student.Sagittarius.xml</td>\n",
       "      <td>\\n\\n     \\n      Sum1 told me about \"Hope\" rec...</td>\n",
       "      <td>04,August,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15910</th>\n",
       "      <td>blogs\\1090235.female.17.indUnk.Aquarius.xml</td>\n",
       "      <td>\\n\\n\\t \\n       wow im writing twice in 2 days...</td>\n",
       "      <td>07,August,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15911</th>\n",
       "      <td>blogs\\1090235.female.17.indUnk.Aquarius.xml</td>\n",
       "      <td>\\n\\n\\t \\n       heyyy :) whats up? it is frida...</td>\n",
       "      <td>06,August,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912</th>\n",
       "      <td>blogs\\1090235.female.17.indUnk.Aquarius.xml</td>\n",
       "      <td>\\n\\n\\t \\n       things are about to change dra...</td>\n",
       "      <td>03,August,2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15913</th>\n",
       "      <td>blogs\\1090547.male.14.Religion.Capricorn.xml</td>\n",
       "      <td>\\n\\n\\t \\n       prounced: \"pett-it\"   Alright,...</td>\n",
       "      <td>09,juillet,2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15914 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  blog  \\\n",
       "0               blogs\\1000331.female.37.indUnk.Leo.xml   \n",
       "1               blogs\\1000331.female.37.indUnk.Leo.xml   \n",
       "2               blogs\\1000331.female.37.indUnk.Leo.xml   \n",
       "3               blogs\\1000331.female.37.indUnk.Leo.xml   \n",
       "4               blogs\\1000331.female.37.indUnk.Leo.xml   \n",
       "...                                                ...   \n",
       "15909  blogs\\1089670.female.17.Student.Sagittarius.xml   \n",
       "15910      blogs\\1090235.female.17.indUnk.Aquarius.xml   \n",
       "15911      blogs\\1090235.female.17.indUnk.Aquarius.xml   \n",
       "15912      blogs\\1090235.female.17.indUnk.Aquarius.xml   \n",
       "15913     blogs\\1090547.male.14.Religion.Capricorn.xml   \n",
       "\n",
       "                                                   posts            dates  \n",
       "0      \\n\\n\\t \\n      My four-year old never stops ta...      29,May,2004  \n",
       "1      \\n\\n\\t \\n      Actually it's not raining yet, ...      28,May,2004  \n",
       "2      \\n\\n\\t \\n      Ha! Just set up my RSS feed - t...      28,May,2004  \n",
       "3      \\n\\n\\t \\n      Oh, which just reminded me, we ...      28,May,2004  \n",
       "4      \\n\\n\\t \\n      I've tried starting blog after ...      28,May,2004  \n",
       "...                                                  ...              ...  \n",
       "15909  \\n\\n     \\n      Sum1 told me about \"Hope\" rec...   04,August,2004  \n",
       "15910  \\n\\n\\t \\n       wow im writing twice in 2 days...   07,August,2004  \n",
       "15911  \\n\\n\\t \\n       heyyy :) whats up? it is frida...   06,August,2004  \n",
       "15912  \\n\\n\\t \\n       things are about to change dra...   03,August,2004  \n",
       "15913  \\n\\n\\t \\n       prounced: \"pett-it\"   Alright,...  09,juillet,2004  \n",
       "\n",
       "[15914 rows x 3 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 37733)\t1\n",
      "  (0, 22590)\t1\n",
      "  (0, 63031)\t1\n",
      "  (0, 39757)\t1\n",
      "  (0, 38474)\t1\n",
      "  (0, 53834)\t1\n",
      "  (0, 55456)\t1\n",
      "  (0, 50360)\t2\n",
      "  (0, 33509)\t2\n",
      "  (0, 49046)\t3\n",
      "  (0, 36817)\t1\n",
      "  (0, 3876)\t1\n",
      "  (0, 61600)\t1\n",
      "  (0, 63101)\t1\n",
      "  (0, 58596)\t2\n",
      "  (0, 39679)\t1\n",
      "  (0, 63019)\t1\n",
      "  (0, 61610)\t1\n",
      "  (0, 17292)\t1\n",
      "  (0, 32238)\t1\n",
      "  (0, 9066)\t1\n",
      "  (0, 26750)\t1\n",
      "  (0, 28595)\t1\n",
      "  (0, 56245)\t1\n",
      "  (0, 45475)\t1\n",
      "  :\t:\n",
      "  (15913, 49398)\t1\n",
      "  (15913, 17866)\t1\n",
      "  (15913, 19059)\t1\n",
      "  (15913, 18799)\t1\n",
      "  (15913, 60662)\t1\n",
      "  (15913, 37825)\t1\n",
      "  (15913, 33873)\t1\n",
      "  (15913, 5627)\t1\n",
      "  (15913, 21311)\t1\n",
      "  (15913, 7158)\t1\n",
      "  (15913, 25425)\t1\n",
      "  (15913, 61398)\t1\n",
      "  (15913, 14839)\t1\n",
      "  (15913, 44596)\t1\n",
      "  (15913, 42225)\t1\n",
      "  (15913, 21290)\t4\n",
      "  (15913, 17302)\t2\n",
      "  (15913, 21291)\t1\n",
      "  (15913, 42230)\t4\n",
      "  (15913, 31901)\t1\n",
      "  (15913, 45187)\t2\n",
      "  (15913, 49198)\t1\n",
      "  (15913, 44921)\t1\n",
      "  (15913, 56336)\t1\n",
      "  (15913, 638)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "tf_matrix = vectorizer.fit_transform(all_posts)\n",
    "print(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "tf_np_matrix = tf_matrix.toarray()\n",
    "print(tf_np_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our collection of 15914 newsgroup posts contain a total of 63921 unique words\n",
      "The newsgroup in row 0 contains 41 unique words.\n",
      "The actual word-counts map to the following column indices:\n",
      "\n",
      "[ 3876  4261  9066 17292 20346 22590 24289 26302 26590 26750 28595 29970\n",
      " 32238 33509 36817 37733 38474 39145 39679 39757 40773 45475 46762 49046\n",
      " 50360 50982 53834 55456 56245 56474 57002 58596 60143 60508 61600 61610\n",
      " 61842 62433 63019 63031 63101]\n",
      "['and', 'anything', 'bugs', 'do', 'exhausting', 'four', 'go', 'hear', 'her', 'hide', 'in', 'is', 'lady', 'll', 'mom', 'my', 'never', 'now', 'oh', 'old', 'own', 'rain', 'remember', 'say', 'she', 'sigh', 'stops', 'talking', 'the', 'this', 'to', 'ummm', 'very', 'voice', 'when', 'where', 'why', 'work', 'yeah', 'year', 'yes']\n",
      "    Word  Count\n",
      "     say      3\n",
      "    ummm      2\n",
      "      to      2\n",
      "     she      2\n",
      "      ll      2\n",
      "    very      2\n",
      "    sigh      1\n",
      "   stops      1\n",
      " talking      1\n",
      "     the      1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_posts, vocabulary_size = tf_matrix.shape\n",
    "print(f\"Our collection of {num_posts} newsgroup posts contain a total of \"\n",
    "      f\"{vocabulary_size} unique words\")\n",
    "\n",
    "import numpy as np\n",
    "tf_vector = tf_np_matrix[0]\n",
    "non_zero_indices = np.flatnonzero(tf_vector)\n",
    "num_unique_words = non_zero_indices.size\n",
    "print(f\"The newsgroup in row 0 contains {num_unique_words} unique words.\")\n",
    "print(\"The actual word-counts map to the following column indices:\\n\")\n",
    "print(non_zero_indices)\n",
    "\n",
    "words = vectorizer.get_feature_names()\n",
    "unique_words = [words[i] for i in non_zero_indices]\n",
    "print(unique_words)\n",
    "\n",
    "import pandas as pd\n",
    "data = {'Word': unique_words,\n",
    "        'Count': tf_vector[non_zero_indices]}\n",
    "\n",
    "df = pd.DataFrame(data).sort_values('Count', ascending=False)\n",
    "print(df[:10].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
